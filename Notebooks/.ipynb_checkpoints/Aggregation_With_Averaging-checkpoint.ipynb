{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afc575-f558-4216-8050-43d4656bffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving wavelength list from a reference file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|████████████████████████| 9/9 [00:00<00:00, 3208.56it/s]\n",
      "PROCESSING TASKS | : 100%|█████████████████████| 9/9 [00:00<00:00, 25420.02it/s]\n",
      "COLLECTING RESULTS | : 100%|████████████████████| 9/9 [00:00<00:00, 9035.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 172 channels.\n",
      "\n",
      "Processing 2024-04-14 (window 2024-04-08 to 2024-04-14)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.7 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.5 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.0 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 11/11 [00:00<00:00, 1023.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 11/11 [00:40<00:00,  3.70s/it]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 11/11 [00:00<00:00, 24450.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240408T181826.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240409T171508.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240409T185328.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240410T175010.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T164652.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T182512.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T172154.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T190014.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-15 (window 2024-04-09 to 2024-04-15)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.7 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.6 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.2 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.0 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.9 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.1 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.9 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.6 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 12/12 [00:00<00:00, 4055.41it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 12/12 [00:00<00:00, 59074.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240409T171508.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240409T185328.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240410T175010.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T164652.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T182512.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T172154.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T190014.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240408T181826.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-16 (window 2024-04-10 to 2024-04-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 11/11 [00:00<00:00, 3751.92it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 11/11 [00:05<00:00,  2.12it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 11/11 [00:00<00:00, 79684.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240410T175010.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T164652.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T182512.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T172154.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T190014.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240409T185328.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240409T171508.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-17 (window 2024-04-11 to 2024-04-17)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.6 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.3 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.6 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.6 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 12/12 [00:00<00:00, 3122.50it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 12/12 [00:09<00:00,  1.30it/s]\n",
      "COLLECTING RESULTS | : 100%|████████████████| 12/12 [00:00<00:00, 103563.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240411T164652.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240411T182512.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T172154.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T190014.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240410T175010.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-18 (window 2024-04-12 to 2024-04-18)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.6 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 11/11 [00:00<00:00, 3355.69it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 11/11 [00:04<00:00,  2.30it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 11/11 [00:00<00:00, 42096.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240412T172154.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240412T190014.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240411T164652.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240411T182512.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-19 (window 2024-04-13 to 2024-04-19)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.1 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.3 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 10/10 [00:00<00:00, 3236.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 10/10 [00:04<00:00,  2.22it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 10/10 [00:00<00:00, 79287.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240412T190014.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240412T172154.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-20 (window 2024-04-14 to 2024-04-20)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.0 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 6.4 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.2 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.3 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 11/11 [00:00<00:00, 3375.33it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 11/11 [00:06<00:00,  1.63it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 11/11 [00:00<00:00, 87381.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240413T175656.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-21 (window 2024-04-15 to 2024-04-21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 10/10 [00:00<00:00, 3267.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 10/10 [00:04<00:00,  2.35it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 10/10 [00:00<00:00, 65741.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240414T165338.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240414T183158.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-22 (window 2024-04-16 to 2024-04-22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|████████████████████████| 9/9 [00:00<00:00, 6827.41it/s]\n",
      "PROCESSING TASKS | : 100%|████████████████████████| 9/9 [00:04<00:00,  1.94it/s]\n",
      "COLLECTING RESULTS | : 100%|███████████████████| 9/9 [00:00<00:00, 73298.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240422T181658.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240415T190657.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240415T172837.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-23 (window 2024-04-17 to 2024-04-23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 10/10 [00:00<00:00, 3538.30it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 10/10 [00:00<00:00, 44620.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240422T181658.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T171338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T185158.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240416T180338.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-24 (window 2024-04-18 to 2024-04-24)\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 5.8 seconds...\n",
      "Search error: {\"errors\":[\"An Internal Error has occurred.\"]}. Retrying in 7.1 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|████████████████████████| 9/9 [00:00<00:00, 6587.91it/s]\n",
      "PROCESSING TASKS | : 100%|████████████████████████| 9/9 [00:04<00:00,  1.83it/s]\n",
      "COLLECTING RESULTS | : 100%|███████████████████| 9/9 [00:00<00:00, 47127.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240422T181658.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T171338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T185158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240424T174837.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240417T183839.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240417T170019.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-25 (window 2024-04-19 to 2024-04-25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|████████████████████████| 9/9 [00:00<00:00, 1580.30it/s]\n",
      "PROCESSING TASKS | : 100%|████████████████████████| 9/9 [00:04<00:00,  1.95it/s]\n",
      "COLLECTING RESULTS | : 100%|███████████████████| 9/9 [00:00<00:00, 70295.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240422T181658.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T171338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T185158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240424T174837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240425T182336.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240418T173520.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-26 (window 2024-04-20 to 2024-04-26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 10/10 [00:00<00:00, 2290.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "COLLECTING RESULTS | : 100%|█████████████████| 10/10 [00:00<00:00, 35971.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240422T181658.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T171338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T185158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240424T174837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240425T182336.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240426T172015.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240426T185835.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240419T181021.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-27 (window 2024-04-21 to 2024-04-27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|████████████████████████| 9/9 [00:00<00:00, 3030.32it/s]\n",
      "PROCESSING TASKS | : 100%|████████████████████████| 9/9 [00:03<00:00,  2.40it/s]\n",
      "COLLECTING RESULTS | : 100%|███████████████████| 9/9 [00:00<00:00, 72593.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data for PACE_OCI.20240421T174202.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240422T181658.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T171338.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240423T185158.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240424T174837.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240425T182336.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240426T172015.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240426T185835.L2.OC_AOP.V3_0.nc\n",
      "Using cached data for PACE_OCI.20240427T175513.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240420T184521.L2.OC_AOP.V3_0.nc\n",
      "Deleted old file: PACE_OCI.20240420T170701.L2.OC_AOP.V3_0.nc\n",
      "\n",
      "Processing 2024-04-28 (window 2024-04-22 to 2024-04-28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 10/10 [00:00<00:00, 1945.95it/s]\n",
      "PROCESSING TASKS | :  90%|████████████████████▋  | 9/10 [00:05<00:00,  1.57it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import earthaccess\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Authenticate\n",
    "auth = earthaccess.login(persist=True)\n",
    "\n",
    "# Parameters\n",
    "bbox = (-83.62, 41.34, -82, 42.27)      # (lon_min, lat_min, lon_max, lat_max)\n",
    "res = 0.01\n",
    "start_date = datetime(2024, 4, 14)\n",
    "end_date = datetime(2025, 5, 23)\n",
    "window_size = 7\n",
    "decay = 0.8\n",
    "\n",
    "# Ensure data directories exist\n",
    "os.makedirs(\"../Data/\", exist_ok=True)\n",
    "os.makedirs(\"../Cache/\", exist_ok=True)\n",
    "os.makedirs(\"../Images/\", exist_ok=True)\n",
    "\n",
    "# Output grid\n",
    "lat_bins = np.arange(bbox[1], bbox[3] + res, res)\n",
    "lon_bins = np.arange(bbox[0], bbox[2] + res, res)\n",
    "lat_centers = 0.5 * (lat_bins[:-1] + lat_bins[1:])\n",
    "lon_centers = 0.5 * (lon_bins[:-1] + lon_bins[1:])\n",
    "nlat, nlon = len(lat_centers), len(lon_centers)\n",
    "\n",
    "# --- Retry Helpers ---\n",
    "\n",
    "def safe_search(short_name, temporal, bounding_box, max_retries=500):\n",
    "    retries = 0\n",
    "    while True:\n",
    "        try:\n",
    "            results = earthaccess.search_data(\n",
    "                short_name=short_name,\n",
    "                temporal=temporal,\n",
    "                bounding_box=bounding_box\n",
    "            )\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(f\"Search failed after {max_retries} retries: {e}\")\n",
    "                return []\n",
    "            wait = 5 + random.uniform(0, 3)\n",
    "            print(f\"Search error: {e}. Retrying in {wait:.1f} seconds...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "def safe_download(results, directory=\"../Data/\", max_retries=5):\n",
    "    retries = 0\n",
    "    while True:\n",
    "        try:\n",
    "            paths = earthaccess.download(results, directory)\n",
    "            return paths\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(f\"Download failed after {max_retries} retries: {e}\")\n",
    "                return []\n",
    "            wait = 5 + random.uniform(0, 3)\n",
    "            print(f\"Download error: {e}. Retrying in {wait:.1f} seconds...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "# Wavelengths from a reference file\n",
    "print(\"Retrieving wavelength list from a reference file...\")\n",
    "search_ref = safe_search(\n",
    "    short_name=\"PACE_OCI_L2_AOP\",\n",
    "    temporal=(\"2024-06-01\", \"2024-06-05\"),\n",
    "    bounding_box=bbox,\n",
    ")\n",
    "if not search_ref:\n",
    "    raise RuntimeError(\"No reference files found to retrieve wavelengths.\")\n",
    "ref_file = safe_download(search_ref, \"../Data/\")[0]\n",
    "wave_all = xr.open_dataset(ref_file, group=\"sensor_band_parameters\")[\"wavelength_3d\"].data\n",
    "num_channels = len(wave_all)\n",
    "print(f\"Found {num_channels} channels.\")\n",
    "\n",
    "# Prepare main array\n",
    "total_days = (end_date - start_date).days + 1\n",
    "ndarray_all = np.full((total_days, nlat, nlon, num_channels), np.nan, dtype=np.float32)\n",
    "\n",
    "# Process day by day\n",
    "for day_idx in range(total_days):\n",
    "    current_date = start_date + timedelta(days=day_idx)\n",
    "    window_start = current_date - timedelta(days=window_size - 1)\n",
    "    window_end = current_date\n",
    "    print(f\"\\nProcessing {current_date.date()} (window {window_start.date()} to {window_end.date()})\")\n",
    "\n",
    "    # Search for data in window (with retry)\n",
    "    results = safe_search(\n",
    "        short_name=\"PACE_OCI_L2_AOP\",\n",
    "        temporal=(window_start.strftime(\"%Y-%m-%d\"), window_end.strftime(\"%Y-%m-%d\")),\n",
    "        bounding_box=bbox,\n",
    "    )\n",
    "\n",
    "    if not results:\n",
    "        print(\"No data found for this window. Skipping to next date.\")\n",
    "        continue\n",
    "\n",
    "    # Download files (with retry)\n",
    "    paths = safe_download(results, \"../Data/\")\n",
    "    if not paths:\n",
    "        print(\"No files downloaded for this window. Skipping to next date.\")\n",
    "        continue\n",
    "\n",
    "    # Initialize sum and weight arrays\n",
    "    sum_all = np.zeros((num_channels, nlat, nlon))\n",
    "    weight_all = np.zeros((num_channels, nlat, nlon))\n",
    "\n",
    "    for path in paths:\n",
    "        base = os.path.basename(path)\n",
    "        date_str = base.split(\".\")[1][:8]\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "        delta_days = (window_end - file_date).days\n",
    "        weight = decay ** delta_days if delta_days >= 0 else 0\n",
    "\n",
    "        cache_file = f\"../Cache/{base}.npz\"\n",
    "\n",
    "        if not os.path.exists(cache_file):\n",
    "            print(f\"Processing {base} (not in cache)\")\n",
    "            try:\n",
    "                nav = xr.open_dataset(path, group=\"navigation_data\")\n",
    "                lat = nav[\"latitude\"].values\n",
    "                lon = nav[\"longitude\"].values\n",
    "\n",
    "                rrs_ds = xr.open_dataset(path, group=\"geophysical_data\")[\"Rrs\"]\n",
    "                rrs_ds = rrs_ds.assign_coords(wavelength_3d=wave_all)\n",
    "\n",
    "                lat_idx_all = []\n",
    "                lon_idx_all = []\n",
    "                ch_idx_all = []\n",
    "                val_all = []\n",
    "\n",
    "                for ch_idx, wl in tqdm(list(enumerate(wave_all)), desc=f\"Channels in {base}\", leave=False):\n",
    "                    band = rrs_ds.sel(wavelength_3d=wl, method=\"nearest\").values\n",
    "                    mask = (\n",
    "                        np.isfinite(band) &\n",
    "                        (lat >= bbox[1]) & (lat <= bbox[3]) &\n",
    "                        (lon >= bbox[0]) & (lon <= bbox[2])\n",
    "                    )\n",
    "                    lat_valid = lat[mask]\n",
    "                    lon_valid = lon[mask]\n",
    "                    val_valid = band[mask]\n",
    "\n",
    "                    lat_idx = np.searchsorted(lat_bins, lat_valid) - 1\n",
    "                    lon_idx = np.searchsorted(lon_bins, lon_valid) - 1\n",
    "\n",
    "                    lat_idx_all.extend(lat_idx)\n",
    "                    lon_idx_all.extend(lon_idx)\n",
    "                    ch_idx_all.extend([ch_idx] * len(val_valid))\n",
    "                    val_all.extend(val_valid)\n",
    "\n",
    "                np.savez_compressed(cache_file,\n",
    "                                    lat_idx=np.array(lat_idx_all, dtype=np.int16),\n",
    "                                    lon_idx=np.array(lon_idx_all, dtype=np.int16),\n",
    "                                    ch_idx=np.array(ch_idx_all, dtype=np.int16),\n",
    "                                    val=np.array(val_all, dtype=np.float32))\n",
    "                print(f\"Cached data to {cache_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {path}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Using cached data for {base}\")\n",
    "\n",
    "        # Load from cache\n",
    "        data = np.load(cache_file)\n",
    "        lat_idx = data['lat_idx']\n",
    "        lon_idx = data['lon_idx']\n",
    "        ch_idx = data['ch_idx']\n",
    "        val = data['val']\n",
    "\n",
    "        for j in range(len(val)):\n",
    "            if 0 <= lat_idx[j] < nlat and 0 <= lon_idx[j] < nlon:\n",
    "                sum_all[ch_idx[j], lat_idx[j], lon_idx[j]] += val[j] * weight\n",
    "                weight_all[ch_idx[j], lat_idx[j], lon_idx[j]] += weight\n",
    "\n",
    "    # Finalize average\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        avg_all = sum_all / weight_all\n",
    "        avg_all[weight_all == 0] = np.nan\n",
    "\n",
    "    ndarray_all[day_idx] = np.transpose(avg_all, (1, 2, 0))\n",
    "\n",
    "    # Delete old files\n",
    "    delete_date = (current_date - timedelta(days=window_size)).strftime('%Y%m%d')\n",
    "    for fname in os.listdir(\"../Data/\"):\n",
    "        if delete_date in fname and fname.endswith(\".nc\"):\n",
    "            try:\n",
    "                os.remove(os.path.join(\"../Data/\", fname))\n",
    "                print(f\"Deleted old file: {fname}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not delete {fname}: {e}\")\n",
    "\n",
    "# Save results\n",
    "np.save(\"../Images/composite_data.npy\", ndarray_all)\n",
    "print(\"\\nSaved full 4D composite data array to '../Images/composite_data.npy'.\")\n",
    "\n",
    "metadata = {\"wavelengths\": wave_all, \"lat\": lat_centers, \"lon\": lon_centers}\n",
    "with open(\"../Images/composite_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(\"Saved metadata (wavelengths, lat, lon) to '../Images/composite_metadata.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d6969-f718-4f40-9af9-249dd0e77441",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wave = xr.open_dataset(paths[0], group=\"sensor_band_parameters\")[\"wavelength_3d\"].data\n",
    "indices = np.where(wave == 450)\n",
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc086c5-7122-45f3-81e2-2c782ed8caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def generate_day_images(n, r_idx=113, g_idx=84, b_idx=42):\n",
    "    \"\"\"\n",
    "    Generate individual true-color images for the first n days in the composite data.\n",
    "    \n",
    "    Args:\n",
    "        n (int): Number of days to generate images for.\n",
    "        r_idx (int): Index of the wavelength to use for red channel.\n",
    "        g_idx (int): Index of the wavelength to use for green channel.\n",
    "        b_idx (int): Index of the wavelength to use for blue channel.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data_path = \"../Images/composite_data.npy\"\n",
    "    meta_path = \"../Images/composite_metadata.pkl\"\n",
    "    if not os.path.exists(data_path) or not os.path.exists(meta_path):\n",
    "        print(\"Required files not found. Run the composite script first.\")\n",
    "        return\n",
    "    \n",
    "    data = np.load(data_path)\n",
    "    print(\"data.shape\", data.shape)\n",
    "    with open(meta_path, \"rb\") as f:\n",
    "        meta = pickle.load(f)\n",
    "    \n",
    "    lat = meta[\"lat\"]\n",
    "    lon = meta[\"lon\"]\n",
    "    wavelengths = meta[\"wavelengths\"]\n",
    "\n",
    "    num_days = data.shape[0]\n",
    "    n = min(n, num_days)  # Ensure n doesn't exceed available data\n",
    "\n",
    "    # Normalize Rrs data (assumed 0-0.03)\n",
    "    def normalize(arr, vmin=0, vmax=0.03):\n",
    "        return np.clip((arr - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "    for day_idx in range(n):\n",
    "        daily_data = data[day_idx]  # shape (h, w, c)\n",
    "\n",
    "        if np.isnan(daily_data).all():\n",
    "            print(f\"Day {day_idx + 1} has no valid data. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        r = normalize(daily_data[:, :, r_idx])\n",
    "        g = normalize(daily_data[:, :, g_idx])\n",
    "        b = normalize(daily_data[:, :, b_idx])\n",
    "\n",
    "        rgb = np.stack([r, g, b], axis=-1)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(rgb, origin=\"lower\", extent=[lon.min(), lon.max(), lat.min(), lat.max()])\n",
    "        plt.title(f\"True-Color Image - Day {day_idx + 1}\")\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = f\"../Images/dayyy_{day_idx + 1:03d}.png\"\n",
    "        plt.savefig(out_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved image: {out_path}\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625720e2-c137-45e6-88b7-f761342b9dbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = generate_day_images(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649b557-ffe8-4ca9-b7ad-8baa86933821",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[3][45][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903c7d4-b244-49c8-b3df-d82ea11672f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5ce5c-1172-4cbb-8c47-25e12f570eb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d9896-4018-4edb-8308-3858765d57b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import earthaccess\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Authenticate\n",
    "auth = earthaccess.login(persist=True)\n",
    "\n",
    "# Parameters\n",
    "selected_wavelengths = [645, 555, 450]  # R, G, B\n",
    "bbox = (-83.62, 41.34, -82, 42.27)      # (lon_min, lat_min, lon_max, lat_max)\n",
    "res = 0.01  # grid resolution in degrees\n",
    "start_date = datetime(2024, 5, 17)\n",
    "end_date = datetime(2025, 5, 23)\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(\"../Images/\", exist_ok=True)\n",
    "os.makedirs(\"../Data/\", exist_ok=True)\n",
    "\n",
    "# Output grid\n",
    "lat_bins = np.arange(bbox[1], bbox[3] + res, res)\n",
    "lon_bins = np.arange(bbox[0], bbox[2] + res, res)\n",
    "lat_centers = 0.5 * (lat_bins[:-1] + lat_bins[1:])\n",
    "lon_centers = 0.5 * (lon_bins[:-1] + lon_bins[1:])\n",
    "nlat, nlon = len(lat_centers), len(lon_centers)\n",
    "\n",
    "# Iterate through each day\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    window_start = current_date - timedelta(days=4)\n",
    "    window_end = current_date\n",
    "    print(f\"Processing window: {window_start.date()} to {window_end.date()}\")\n",
    "\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=\"PACE_OCI_L2_AOP\",\n",
    "        temporal=(window_start.strftime(\"%Y-%m-%d\"), window_end.strftime(\"%Y-%m-%d\")),\n",
    "        bounding_box=bbox,\n",
    "    )\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No data for {window_end.strftime('%Y-%m-%d')}. Skipping.\")\n",
    "        current_date += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    paths = earthaccess.download(results, \"../Data/\")\n",
    "\n",
    "    if not paths:\n",
    "        print(f\"No files downloaded for {window_end.strftime('%Y-%m-%d')}. Skipping.\")\n",
    "        current_date += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    # Initialize sum and count arrays\n",
    "    sum_rgb = np.zeros((3, nlat, nlon))\n",
    "    count_rgb = np.zeros((3, nlat, nlon))\n",
    "\n",
    "    try:\n",
    "        wave = xr.open_dataset(paths[0], group=\"sensor_band_parameters\")[\"wavelength_3d\"].data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read wavelength data: {e}\")\n",
    "        current_date += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    # Process each file\n",
    "    for path in paths:\n",
    "        print(f\"Processing {path}\")\n",
    "        try:\n",
    "            rrs_ds = xr.open_dataset(path, group=\"geophysical_data\")[\"Rrs\"]\n",
    "            rrs_ds = rrs_ds.assign_coords(wavelength_3d=wave)\n",
    "\n",
    "            nav = xr.open_dataset(path, group=\"navigation_data\")\n",
    "            lat = nav[\"latitude\"].values\n",
    "            lon = nav[\"longitude\"].values\n",
    "\n",
    "            for b, wl in enumerate(selected_wavelengths):\n",
    "                band = rrs_ds.sel(wavelength_3d=wl, method=\"nearest\").values\n",
    "                mask = (\n",
    "                    np.isfinite(band) &\n",
    "                    (lat >= bbox[1]) & (lat <= bbox[3]) &\n",
    "                    (lon >= bbox[0]) & (lon <= bbox[2])\n",
    "                )\n",
    "\n",
    "                lat_valid = lat[mask]\n",
    "                lon_valid = lon[mask]\n",
    "                val_valid = band[mask]\n",
    "\n",
    "                lat_idx = np.searchsorted(lat_bins, lat_valid) - 1\n",
    "                lon_idx = np.searchsorted(lon_bins, lon_valid) - 1\n",
    "\n",
    "                for j in range(len(val_valid)):\n",
    "                    if 0 <= lat_idx[j] < nlat and 0 <= lon_idx[j] < nlon:\n",
    "                        sum_rgb[b, lat_idx[j], lon_idx[j]] += val_valid[j]\n",
    "                        count_rgb[b, lat_idx[j], lon_idx[j]] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {path}: {e}\")\n",
    "\n",
    "    # Compute mean reflectance\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        mean_rgb = sum_rgb / count_rgb\n",
    "        mean_rgb = np.nan_to_num(mean_rgb, nan=0.0)\n",
    "\n",
    "    # Normalize reflectance for display (Rrs units are ~0–0.03)\n",
    "    def normalize(arr, vmin=0, vmax=0.03):\n",
    "        return np.clip((arr - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "    r = normalize(mean_rgb[0])\n",
    "    g = normalize(mean_rgb[1])\n",
    "    b = normalize(mean_rgb[2])\n",
    "    rgb = np.stack([r, g, b], axis=-1)\n",
    "\n",
    "    # Save true color image\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(rgb, origin=\"lower\", extent=[bbox[0], bbox[2], bbox[1], bbox[3]])\n",
    "    plt.title(f\"5-Day Composite Ending {window_end.strftime('%Y-%m-%d')}\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.tight_layout()\n",
    "    out_path = f\"../Images/{window_end.strftime('%Y%m%d')}.png\"\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved image: {out_path}\")\n",
    "\n",
    "    # Clean up only the earliest date in window\n",
    "    delete_date = window_start.strftime('%Y%m%d')\n",
    "    for fname in os.listdir(\"../Data/\"):\n",
    "        if delete_date in fname and fname.endswith(\".nc\"):\n",
    "            try:\n",
    "                os.remove(os.path.join(\"../Data/\", fname))\n",
    "                print(f\"Deleted old file: {fname}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not delete {fname}: {e}\")\n",
    "\n",
    "    current_date += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17e289-34f7-495b-a54d-b72a044f0427",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
