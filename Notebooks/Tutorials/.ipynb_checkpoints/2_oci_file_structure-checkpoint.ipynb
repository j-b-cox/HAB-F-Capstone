{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43bf567d-6b45-427c-b70c-8d72be833aeb",
   "metadata": {},
   "source": [
    "# File Structure at Three Processing Levels for the Ocean Color Instrument (OCI)\n",
    "\n",
    "**Authors:** Anna Windle (NASA, SSAI), Ian Carroll (NASA, UMBC), Carina Poulin (NASA, SSAI)\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "\n",
    "The following notebooks are **prerequisites** for this tutorial.\n",
    "\n",
    "- Learn with OCI: [Data Access][oci-data-access]\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "An [Earthdata Login][edl] account is required to access data from the NASA Earthdata system, including NASA ocean color data.\n",
    "\n",
    "</div>\n",
    "\n",
    "[edl]: https://urs.earthdata.nasa.gov/\n",
    "[oci-data-access]: https://oceancolor.gsfc.nasa.gov/resources/docs/tutorials/notebooks/oci_data_access/\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this example we will use the `earthaccess` package to access OCI Level-1B (L1B), Level-2 (L2), and Level-3 (L3) NetCDF files and open them using `xarray`.\n",
    "\n",
    "**NetCDF** ([Network Common Data Format][netcdf]) is a binary file format for storing multidimensional scientific data (variables). It is optimized for array-oriented data access and support a machine-independent format for representing scientific data. Files ending in `.nc` are NetCDF files.\n",
    "\n",
    "**XArray** is a [package][xarray] that supports the use of multi-dimensional arrays in Python. It is widely used to handle Earth observation data, which often involves multiple dimensions — for instance, longitude, latitude, time, and channels/bands.\n",
    "\n",
    "[netcdf]: https://www.unidata.ucar.edu/software/netcdf/\n",
    "[xarray]: https://docs.xarray.dev/\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "At the end of this notebok you will know:\n",
    "* How to find groups in a NetCDF file\n",
    "* How to use `xarray` to open OCI data\n",
    "* What key variables are present in the groups within OCI L1B, L2, and L3 files\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "1. [Explore L1B File Structure](#l1b)\n",
    "1. [Explore L2 File Structure](#l2)\n",
    "1. [Explore L3 File Structure](#l3)\n",
    "\n",
    "<a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed6190-246b-4189-84d5-1f511477678b",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Begin by importing all of the packages used in this notebook. If your kernel uses an environment defined following the guidance on the [tutorials] page, then the imports will be successful.\n",
    "\n",
    "[tutorials]: https://oceancolor.gsfc.nasa.gov/resources/docs/tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b832fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import earthaccess\n",
    "import h5netcdf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149abe74-2552-43b0-b983-c867456f4334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jessecox/Desktop/Capstone/HAB-F-Capstone/Notebooks/Tutorials'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6082bc6",
   "metadata": {},
   "source": [
    "Set (and persist to your user profile on the host, if needed) your Earthdata Login credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0444d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207edf5-d1fa-4d0b-a18e-f7f976ba4fdb",
   "metadata": {},
   "source": [
    "[back to top](#contents) <a name=\"l1b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c141a6",
   "metadata": {},
   "source": [
    "## 2. Explore L1B File Structure\n",
    "\n",
    "Let's use `xarray` to open up a OCI L1B NetCDF file using `earthaccess`. We will use the same search method used in <a href=\"oci_data_access.html\">OCI Data Access</a>. Note that L1B files do not include cloud coverage metadata, so we cannot use that filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459a7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (\"2024-05-01\", \"2024-05-16\")\n",
    "bbox = (-76.75, 36.97, -75.74, 39.01)\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L1B_SCI\",\n",
    "    temporal=tspan,\n",
    "    bounding_box=bbox,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b953dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████████████████| 24/24 [00:00<00:00, 4916.88it/s]\n",
      "PROCESSING TASKS | : 100%|██████████████████████| 24/24 [06:36<00:00, 16.52s/it]\n",
      "COLLECTING RESULTS | : 100%|██████████████████| 24/24 [00:00<00:00, 8238.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Data/PACE_OCI.20240501T165311.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240501T165811.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240501T183131.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240502T172807.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240504T165938.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240504T170438.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240504T183758.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240505T173434.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240506T163110.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240506T163610.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240506T180930.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240508T174100.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240509T163735.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240509T164235.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240509T181555.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240510T171230.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240511T174724.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240512T164359.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240512T182218.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240513T171853.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240514T175346.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240515T165020.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240515T182840.L1B.V3.nc',\n",
       " '../Data/PACE_OCI.20240516T172513.L1B.V3.nc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = earthaccess.download(results, '../../Data/')\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2d341",
   "metadata": {},
   "source": [
    "We want to confirm we are running code on a remote host with direct access to the NASA Earthdata Cloud. The next cell has\n",
    "no effect if we are, and otherwise raises an error. If there is an error, consider the substitution explained in the [Data Access][data-access] notebook.\n",
    "\n",
    "[data-access]: https://oceancolor.gsfc.nasa.gov/resources/docs/tutorials/notebooks/oci_data_access/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdac5add",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241m.\u001b[39mbucket\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'f'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     paths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mbucket\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result opened without an S3FileSystem.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    paths[0].f.bucket\n",
    "except AttributeError:\n",
    "    raise \"The result opened without an S3FileSystem.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65a373",
   "metadata": {},
   "source": [
    "Let's open the first file of the L1B files list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943fc648",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (truncated file: eof = 936378368, sblock->base_addr = 0, stored_eof = 1863228096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'h5netcdf.core.File'>, ('/Users/jessecox/Desktop/Capstone/HAB-F-Capstone/Notebooks/Data/PACE_OCI.20240501T165311.L1B.V3.nc',), 'r', (('decode_vlen_strings', True), ('driver', None), ('invalid_netcdf', None)), '8dbb04af-7d73-4b29-8e56-e5445d2e9d14']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataset\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/api.py:611\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    600\u001b[0m     decode_cf,\n\u001b[1;32m    601\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    608\u001b[0m )\n\u001b[1;32m    610\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 611\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    618\u001b[0m     backend_ds,\n\u001b[1;32m    619\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    630\u001b[0m )\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/h5netcdf_.py:406\u001b[0m, in \u001b[0;36mH5netcdfBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, format, group, lock, invalid_netcdf, phony_dims, decode_vlen_strings, driver, driver_kwds)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    387\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m     driver_kwds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    404\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    405\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 406\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mH5NetCDFStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphony_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphony_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_vlen_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_vlen_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    420\u001b[0m     ds \u001b[38;5;241m=\u001b[39m store_entrypoint\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m    421\u001b[0m         store,\n\u001b[1;32m    422\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/h5netcdf_.py:184\u001b[0m, in \u001b[0;36mH5NetCDFStore.open\u001b[0;34m(cls, filename, mode, format, group, lock, autoclose, invalid_netcdf, phony_dims, decode_vlen_strings, driver, driver_kwds)\u001b[0m\n\u001b[1;32m    181\u001b[0m         lock \u001b[38;5;241m=\u001b[39m combine_locks([HDF5_LOCK, get_write_lock(filename)])\n\u001b[1;32m    183\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(h5netcdf\u001b[38;5;241m.\u001b[39mFile, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/h5netcdf_.py:130\u001b[0m, in \u001b[0;36mH5NetCDFStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# todo: utilizing find_root_and_group seems a bit clunky\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#  making filename available on h5netcdf.Group seems better\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m find_root_and_group(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfilename\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock \u001b[38;5;241m=\u001b[39m ensure_lock(lock)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/h5netcdf_.py:195\u001b[0m, in \u001b[0;36mH5NetCDFStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/h5netcdf_.py:187\u001b[0m, in \u001b[0;36mH5NetCDFStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_h5netcdf_create_group\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/h5netcdf/core.py:1522\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, path, mode, invalid_netcdf, phony_dims, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preexisting_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path) \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5py \u001b[38;5;241m=\u001b[39m h5py\n\u001b[0;32m-> 1522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h5file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_h5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, h5py\u001b[38;5;241m.\u001b[39mFile):\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preexisting_file \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 936378368, sblock->base_addr = 0, stored_eof = 1863228096)"
     ]
    }
   ],
   "source": [
    "dataset = xr.open_dataset(paths[0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbfc4b",
   "metadata": {},
   "source": [
    "Notice that this `xarray.Dataset` has nothing but \"Attributes\". We cannot use `xarray` to open multi-group hierarchies or list groups within a NetCDF file, but it can open a specific group if you know its path. The `xarray-datatree` package is going to be merged into `xarray` in the not too distant future, which will allow `xarray` to open the entire hieerarchy. In the meantime, we can use a lower level reader to see the top-level groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5netcdf.File(paths[0]) as file:\n",
    "    groups = list(file)\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210f2a5",
   "metadata": {},
   "source": [
    "Let's open the \"observation_data\" group, which contains the core science variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(paths[0], group=\"observation_data\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82539346",
   "metadata": {},
   "source": [
    "Now you can view the Dimensions, Coordinates, and Variables of this group. To show/hide attributes, press the paper icon on the right hand side of each variable. To show/hide data representation, press the cylinder icon. For instance, you could check the attributes on \"rhot_blue\" to see that this variable is the \"Top of Atmosphere Blue Band Reflectance\".\n",
    "\n",
    "The dimensions of the \"rhot_blue\" variable are (\"blue_bands\", \"number_of_scans\", \"ccd_pixels\"), and it has shape (119, 1709, 1272). The `sizes` attribute of a variable gives us that information as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"rhot_blue\"].sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3802b01a",
   "metadata": {},
   "source": [
    "Let's plot the reflectance at postion 100 in the \"blue_bands\" dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2ecc2-f6c1-482c-ae48-3a5f79dbfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = dataset[\"rhot_blue\"].sel({\"blue_bands\": 100}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787e534-fe8d-4a1a-92b0-d4fa7db1b6a6",
   "metadata": {},
   "source": [
    "[back to top](#contents) <a name=\"l2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb4de3",
   "metadata": {},
   "source": [
    "## 3. Explore L2 File Structure\n",
    "\n",
    "OCI L2 files include retrievals of geophysical variables, such as Apparent Optical Properties (AOP), for each L1 swath. We'll use the same `earthaccess` search for L2 AOP data. Although now we can use `cloud_cover` too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff545a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (\"2024-05-01\", \"2024-05-16\")\n",
    "bbox = (-76.75, 36.97, -75.74, 39.01)\n",
    "clouds = (0, 50)\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L2_AOP_NRT\",\n",
    "    temporal=tspan,\n",
    "    bounding_box=bbox,\n",
    "    cloud_cover=clouds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e22bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5netcdf.File(paths[0]) as file:\n",
    "    groups = list(file)\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4991c9c",
   "metadata": {},
   "source": [
    "Let's look at the \"geophysical_data\" group, which is a new group generated by the level 2 processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(paths[0], group=\"geophysical_data\")\n",
    "rrs = dataset[\"Rrs\"]\n",
    "rrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs.sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1100ce",
   "metadata": {},
   "source": [
    "The Rrs variable has length 184 in the wavelength dimension, so the blue, red, and SWIR wavelengths have been combined. Let's map the Rrs at \"wavelength_3d\" position 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0494a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = rrs.sel({\"wavelength_3d\": 100}).plot(cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90998b",
   "metadata": {},
   "source": [
    "Right now, the scene is being plotted using `number_of_lines` and `pixels_per_line` as \"x\" and \"y\", respectively. We need to add latitude and longitude values to create a true map. To do this, we will create a merged `xarray.Dataset` that pulls in information from the \"navigation_data\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(paths[0], group=\"navigation_data\")\n",
    "dataset = dataset.set_coords((\"longitude\", \"latitude\"))\n",
    "dataset = dataset.rename({\"pixel_control_points\": \"pixels_per_line\"})\n",
    "dataset = xr.merge((rrs, dataset.coords))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df410885",
   "metadata": {},
   "source": [
    "Although we now have coordinates, they won't immediately help because the data are not gridded by latitude and longitude.\n",
    "The Level 2 data cover the original instrument swath and have not been resampled to a regular grid. Therefore latitude\n",
    "and longitude are known, but cannot be used immediately to \"look-up\" values like you can along an array's dimensions.\n",
    "\n",
    "Let's make a scatter plot of the pixel locations so we can see the irregular spacing. By selecting a `slice` with a step size larger than one, we get a subset of the locations for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48170e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = dataset.sel(\n",
    "    {\n",
    "        \"number_of_lines\": slice(None, None, 1720 // 20),\n",
    "        \"pixels_per_line\": slice(None, None, 1272 // 20),\n",
    "    },\n",
    ").plot.scatter(x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9f382",
   "metadata": {},
   "source": [
    "Let's plot this new `xarray.Dataset` the same way as before, but add latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs = dataset[\"Rrs\"].sel({\"wavelength_3d\": 100})\n",
    "plot = rrs.plot(x=\"longitude\", y=\"latitude\", cmap=\"viridis\", vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9a8db",
   "metadata": {},
   "source": [
    "Now you can project the data onto a grid. If you wanna get fancy, add a coastline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfde548",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "rrs.plot(x=\"longitude\", y=\"latitude\", cmap=\"viridis\", vmin=0, ax=ax)\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01838a6",
   "metadata": {},
   "source": [
    "Let's plot the full \"Rrs\" spectrum for individual pixels. A visualization with all the pixels\n",
    "wouldn't be useful, but limiting to a bounding box gives a simple way to subset pixels. Note that,\n",
    "since we still don't have gridded data (i.e. our latitude and longitude coordinates are two-dimensional),\n",
    "we can't `slice` on a built-in index. Without getting into anything complex, we can just box it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a991b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs_box = dataset[\"Rrs\"].where(\n",
    "    (\n",
    "        (dataset[\"latitude\"] > 37.52)\n",
    "        & (dataset[\"latitude\"] < 37.55)\n",
    "        & (dataset[\"longitude\"] > -75.46)\n",
    "        & (dataset[\"longitude\"] < -75.43)\n",
    "    ),\n",
    "    drop=True,\n",
    ")\n",
    "rrs_box.sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b56c92",
   "metadata": {},
   "source": [
    "The line plotting method will only draw a line plot for 1D data, which we can get by stacking\n",
    "our two spatial dimensions and choosing to show the new \"pixel dimension\" as different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eec1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs_stack = rrs_box.stack(\n",
    "    {\"pixel\": [\"number_of_lines\", \"pixels_per_line\"]},\n",
    "    create_index=False,\n",
    ")\n",
    "plot = rrs_stack.plot.line(hue=\"pixel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832dc749",
   "metadata": {},
   "source": [
    "We will go over how to plot Rrs spectra with accurate wavelength values on the x-axis in an upcoming notebook.\n",
    "\n",
    "[back to top](#contents) <a name=\"l3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98156f66-d662-478e-bd3b-6b9b2ffd578a",
   "metadata": {},
   "source": [
    "## 4. Explore L3 File Structure\n",
    "\n",
    "At Level-3 there are binned (B) and mapped (M) products available for OCI. The L3M remote sensing reflectance (Rrs) files contain global maps of Rrs. We'll use the same `earthaccess` method to find the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (\"2024-05-01\", \"2024-05-16\")\n",
    "bbox = (-76.75, 36.97, -75.74, 39.01)\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L3M_RRS_NRT\",\n",
    "    temporal=tspan,\n",
    "    bounding_box=bbox,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f375ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b308e418",
   "metadata": {},
   "source": [
    "OCI L3 data do not have any groups, so we can open the dataset without the `group` argument.\n",
    "Let's take a look at the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(paths[0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d4800",
   "metadata": {},
   "source": [
    "Notice that OCI L3M data has `lat` and `lon` coordinates, so it's easy to slice out a bounding box and map the \"Rrs_442\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b4225-2bb8-4d79-8901-7cfe4df4e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrs_442 = dataset[\"Rrs_442\"].sel({\"lat\": slice(-25, -45), \"lon\": slice(10, 30)})\n",
    "rrs_442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0293716-0a37-4898-abb5-9ed7b349e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "rrs_442.plot(cmap=\"viridis\", vmin=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd1c7a-df29-4be7-ad46-f02beaacc53a",
   "metadata": {},
   "source": [
    "Also becuase the L3M variables have `lat` and `lon` coordinates, it's possible to stack multiple granules along a\n",
    "new dimension that corresponds to time.\n",
    "Instead of `xr.open_dataset`, we use `xr.open_mfdataset` to create a single `xarray.Dataset` (the \"mf\" in `open_mfdataset` stands for multiple files) from an array of paths.\n",
    "\n",
    "We also use a new search filter available in `search_data`: the `granule_name` argument accepts strings with the \"*\" wildcard. We need this to distinguish daily (\"DAY\") from eight-day (\"8D\") composites, as well as to get the 0.1 degree resolution projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac643cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (\"2024-05-01\", \"2024-05-8\")\n",
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L3M_CHL_NRT\",\n",
    "    temporal=tspan,\n",
    "    granule_name=\"*.DAY.*.0p1deg.*\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ad5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc47be",
   "metadata": {},
   "source": [
    "The `paths` list is sorted temporally by default, which means the shape of the `paths` array specifies the way we need to tile the files together into larger arrays. We specify `combine=\"nested\"` to combine the files according to the shape of the array of files (or file-like objects), even though `paths` is not a \"nested\" list in this case. The `concat_dim=\"date\"` argument generates a new dimension in the combined dataset, because \"date\" is not an existing dimension in the individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61459815",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_mfdataset(\n",
    "    paths,\n",
    "    combine=\"nested\",\n",
    "    concat_dim=\"date\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb68a5",
   "metadata": {},
   "source": [
    "Add a date dimension using the dates from the netCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [xr.open_dataset(a).attrs[\"time_coverage_end\"] for a in paths]\n",
    "dt = pd.to_datetime(dates)\n",
    "dataset = dataset.assign_coords(date=dt.values)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a66cc",
   "metadata": {},
   "source": [
    "A common reason to generate a single dataset from multiple, daily images is to create a composite. Compare the map from a single day ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7810952",
   "metadata": {},
   "outputs": [],
   "source": [
    "chla = np.log10(dataset[\"chlor_a\"])\n",
    "chla.attrs.update(\n",
    "    {\n",
    "        \"units\": f'log({dataset[\"chlor_a\"].attrs[\"units\"]})',\n",
    "    }\n",
    ")\n",
    "plot = chla.sel(date = \"2024-05-02\").plot(aspect=2, size=4, cmap=\"GnBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6defc",
   "metadata": {},
   "source": [
    "... to a map of average values, skipping \"NaN\" values that result from clouds and the OCI's tilt maneuver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92204dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chla_avg = chla.mean(\"date\", keep_attrs=True)\n",
    "plot = chla_avg.plot(aspect=2, size=4, cmap=\"GnBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c50c87",
   "metadata": {},
   "source": [
    "We can also create a time series of mean values over the whole region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b00f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "chla_avg = chla.mean(dim=[\"lon\", \"lat\"], keep_attrs=True)\n",
    "plot = chla_avg.plot(linestyle='-', marker='o', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc7bcc",
   "metadata": {},
   "source": [
    "[back to top](#contents)\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "You have completed the notebook on OCI file structure.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
