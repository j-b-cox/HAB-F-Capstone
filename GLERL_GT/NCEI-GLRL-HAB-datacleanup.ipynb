{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2b83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79097191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom conversion function to convert numerical strings to floats.\n",
    "# For strings starting with the '<' sign, just divide the number by 10 to \n",
    "# make it much smaller than the rest of the dataset.\n",
    "def custom_convert(val):\n",
    "    if isinstance(val, str) and val.strip().startswith('<'):\n",
    "        numstr = val.split('<')[1]\n",
    "        val=float(numstr)\n",
    "        return(val/10)\n",
    "    if isinstance(val, str) and val in [\"bdl\", \"\"]:\n",
    "        return float(0.01)\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return None  # or np.nan if you prefer\n",
    "\n",
    "\n",
    "def convert_strings_to_float(df):\n",
    "    custom_convert_columns = ['particulate_microcystin', 'dissolved_microcystin', 'total_dissolved_p',\n",
    "                             'extracted_phycocyanin', 'soluble_reactive_p', 'extracted_chla', 'ammonia', 'nitrate_nitrite']\n",
    "\n",
    "    # Apply to columns that have datatype as object\n",
    "    for column in custom_convert_columns:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].apply(custom_convert)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8046dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_to_match_2021(df):\n",
    "    dflocal = df.rename(columns={'Date': 'date',\n",
    "                            'Site': 'station_name',\n",
    "                            'Local Time (Eastern Time Zone)': 'time',\n",
    "                            'Arrival_Time': 'time',\n",
    "                            'Latitude (decimal deg)': 'lat',\n",
    "                            'Lat_deg' : 'lat',\n",
    "                            'Long_deg' : 'lon',\n",
    "                            'Longitude (decimal deg)': 'lon',\n",
    "                            'Particulate Microcystin (µg/L)': 'particulate_microcystin',\n",
    "                            'Dissolved Microcystin (µg/L)': 'dissolved_microcystin',\n",
    "                            'Extracted Phycocyanin (µg/L)': 'extracted_phycocyanin',\n",
    "                            'Extracted Chlorophyll a (µg/L)': 'extracted_chla',\n",
    "                            'Turbidity (NTU)': 'turbidity',\n",
    "                            'Total Suspended Solids (mg/L)': 'tss',\n",
    "                            'Volatile Suspended Solids (mg/L)': 'vss',\n",
    "                            'Total Phosphorus (µg P/L)': 'total_p',\n",
    "                            'Total Dissolved Phosphorus (µg P/L)': 'total_dissolved_p',\n",
    "                            'Soluble Reactive Phosphorus (µg P/L)': 'soluble_reactive_p',\n",
    "                            'Ammonia (µg N/L)': 'ammonia',\n",
    "                            'Nitrate + Nitrite (mg N/L)': 'nitrate_nitrite',\n",
    "                            'Particulate Organic Carbon (mg/L)': 'particulate_organic_c',\n",
    "                            'Particulate Organic Nitrogen (mg/L)': 'particulate_organic_n',\n",
    "                            'Colored Dissolved Organic Material absorbance (m-1) at 400nm ': 'cdom',\n",
    "                            'Sample Depth (m)' : 'sample_depth_m',\n",
    "                            'Particulate_Microcystin_ugL-1' : 'particulate_microcystin',\n",
    "                            'Extracted_CHLa_ugL-1' : 'extracted_chla',\n",
    "                            'Sample_Depth_m' : 'sample_depth_m',\n",
    "                            'Dissolved_Microcystin_ugL-1' : 'dissolved_microcystin'\n",
    "                           })\n",
    "    return dflocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be355d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_lat_lon(df):\n",
    "    station_dict = {\n",
    "    \"WE2\": (41.762,-83.33), \n",
    "    \"WE4\": (41.827,-83.193),\n",
    "    \"WE6\": (41.705,-83.385),\n",
    "    \"WE8\": (41.834,-83.364),\n",
    "    \"WE9\": (41.718,-83.424),\n",
    "    \"WE12\": (41.703,-83.254),\n",
    "    \"WE13\": (41.741,-83.136),\n",
    "    \"WE16\": (41.66,-83.143)\n",
    "    }\n",
    "    \n",
    "    # Replace empty strings with NA for consistent missing handling\n",
    "#    df['lat'].replace('', np.nan, inplace=True)\n",
    "#    df['lon'].replace('', np.nan, inplace=True)\n",
    "    df['lat'] = df['lat'].replace('', np.nan)\n",
    "    df['lon'] = df['lon'].replace('', np.nan)\n",
    "\n",
    "\n",
    "    # Apply imputation: fill in missing lat/lon using the dictionary\n",
    "    df['lat'] = df.apply(\n",
    "        lambda row: station_dict[row['station_name']][0]\n",
    "        if pd.isna(row['lat']) and row['station_name'] in station_dict else row['lat'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df['lon'] = df.apply(\n",
    "        lambda row: station_dict[row['station_name']][1]\n",
    "        if pd.isna(row['lon']) and row['station_name'] in station_dict else row['lon'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ef6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_timestamp_and_geocoordinates(df):\n",
    "    df['lat'] = df['lat'].astype(float)\n",
    "    df['lon'] = df['lon'].astype(float)\n",
    "\n",
    "    # Combine and convert to datetime64\n",
    "    df['time'] = df['time'].fillna('00:00')\n",
    "    df['timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "    #df = df.drop(columns=['date', 'time'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd03769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subset_columns(df):\n",
    "    subset = ['station_name', 'timestamp', 'lat', 'lon', \n",
    "              'particulate_microcystin', 'extracted_chla', 'dissolved_microcystin']\n",
    "\n",
    "    df = df[subset]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8263a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filelist = [\n",
    "    './data/lake_erie_habs_field_sampling_results_2012_2018.csv',\n",
    "    './data/lake_erie_habs_field_sampling_results_2019.csv',\n",
    "    './data/noaa-glerl-erie-habs-field-sampling-results-2020-2021.csv',\n",
    "    './data/noaa-glerl-erie-habs-field-sampling-results-2022.csv',\n",
    "    './data/noaa-glerl-erie-habs-field-sampling-transects-results-2021.csv',\n",
    "    './data/noaa-glerl-erie-habs-field-sampling-transects-results-2022.csv',\n",
    "    './data/2024_WLE_Weekly_Datashare_CSV.csv',\n",
    "    './data/2025_WLE_Weekly_Datashare_CSV.csv',\n",
    "]\n",
    "\n",
    "multiyear_df = pd.DataFrame()\n",
    "\n",
    "for file in filelist:\n",
    "    df = pd.read_csv(file, encoding='latin1')\n",
    "    df = rename_columns_to_match_2021(df)\n",
    "    if 'transects' in file:\n",
    "        df['station_name'] = 'Transect'\n",
    "        df['extracted_phycocyanin'] = 0\n",
    "    df = df[df['sample_depth_m'] < 2]\n",
    "    df = handle_timestamp_and_geocoordinates(df)\n",
    "    df = convert_strings_to_float(df)\n",
    "    df = extract_subset_columns(df)\n",
    "    df = handle_missing_lat_lon(df)\n",
    "    multiyear_df = pd.concat([multiyear_df, df], ignore_index=True)\n",
    "\n",
    "multiyear_df.loc[multiyear_df.particulate_microcystin.isna(), 'particulate_microcystin'] = float(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba32419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiyear_df.to_csv(\"./glrl-hab-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
